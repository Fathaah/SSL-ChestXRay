{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SSs0NTurVTkM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from efficientunet import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "import kornia\n",
    "from kornia.augmentation import *\n",
    "from kornia.utils import get_cuda_or_mps_device_if_available, tensor_to_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "omt2lmhwVO03"
   },
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 use_bias = True,\n",
    "                 use_bn = False,\n",
    "                 **kwargs):\n",
    "        super(LinearLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = use_bias\n",
    "        self.use_bn = use_bn\n",
    "\n",
    "        self.linear = nn.Linear(self.in_features,\n",
    "                                self.out_features,\n",
    "                                bias = self.use_bias and not self.use_bn)\n",
    "        if self.use_bn:\n",
    "             self.bn = nn.BatchNorm1d(self.out_features)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class ProjectionHead(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features,\n",
    "                 out_features,\n",
    "                 head_type = 'nonlinear',\n",
    "                 **kwargs):\n",
    "        super(ProjectionHead,self).__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.head_type = head_type\n",
    "\n",
    "        if self.head_type == 'linear':\n",
    "            self.layers = LinearLayer(self.in_features,self.out_features,False, True)\n",
    "        elif self.head_type == 'nonlinear':\n",
    "            self.layers = nn.Sequential(\n",
    "                LinearLayer(self.in_features,self.hidden_features,True, True),\n",
    "                nn.ReLU(),\n",
    "                LinearLayer(self.hidden_features,self.out_features,False,True))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "class PreModel(torch.nn.Module):\n",
    "    def __init__(self,base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.conv_layer = nn.Conv2d(in_channels=1536, out_channels=120, kernel_size=(2,2), stride=(1,1), padding='same')\n",
    "        for p in self.base_model.parameters():\n",
    "            p.requires_grad = True\n",
    "        self.projector = ProjectionHead(5880, 2048, 128)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.base_model(x)\n",
    "        out = self.conv_layer(out)\n",
    "        out_flat = out.view(out.size(0), -1)\n",
    "        xp = self.projector(torch.squeeze(out_flat))\n",
    "\n",
    "        return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c8usOjzVS1Z",
    "outputId": "bbcb0ce5-916a-4c8a-8a0f-68aa4d49dd5d"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "b3unet = get_efficientunet_b3(out_channels=1, concat_input=True, pretrained=True)\n",
    "model = PreModel(b3unet.encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_drMHO9XSUA-"
   },
   "outputs": [],
   "source": [
    "class NewModel(torch.nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.conv_layer = nn.Conv2d(in_channels=1536, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding='same')\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 1024),\n",
    "            nn.BatchNorm1d(1024),  # Add BatchNorm1d\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Add Dropout for regularization\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        # Freeze the weights of the base model\n",
    "        # for param in self.base_model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base_model(x)\n",
    "        out = self.conv_layer(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear_layers(out)\n",
    "        return out\n",
    "\n",
    "new_model = NewModel(model.base_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iO0RQU_5TJRB"
   },
   "outputs": [],
   "source": [
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(new_model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zHLLE6WpLRMM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class QULungsData(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labels = ['COVID-19', 'Non-COVID', 'Normal']\n",
    "        self.labels_dict = {'COVID-19':0, 'Non-COVID':0, 'Normal':1}\n",
    "        self.image_folder = 'images'\n",
    "        self.mask_folder = 'lung masks'\n",
    "        self.img_type = kornia.io.ImageLoadType.GRAY32\n",
    "        self.randomperspective = RandomPerspective(0.3, \"nearest\", align_corners=True, same_on_batch=False,keepdim=True, p=0.5)\n",
    "        self.randomHorizontalflip = RandomHorizontalFlip(same_on_batch=False, keepdim=True, p=0.6, p_batch=0.5)\n",
    "        self.randomElastic = RandomElasticTransform(alpha=(0.3, 0.3), p=0.5, keepdim=True)\n",
    "        self.randomRotation = RandomRotation(degrees=20.0, p=0.5,keepdim=True)\n",
    "        self.randomJigsaw = RandomJigsaw((4, 4), p = 0.3, keepdim=True)\n",
    "        self.image_files = []\n",
    "        self.mask_files = []\n",
    "\n",
    "        for label in self.labels:\n",
    "          image_path = os.path.join(self.root_dir, label, self.image_folder)\n",
    "          mask_path = os.path.join(self.root_dir, label, self.mask_folder)\n",
    "\n",
    "          image_files = os.listdir(image_path)\n",
    "          mask_files = os.listdir(mask_path)\n",
    "\n",
    "          self.image_files += ([[os.path.join(image_path, file), label] for file in image_files])\n",
    "          self.mask_files += ([os.path.join(mask_path, file) for file in mask_files])\n",
    "\n",
    "        self.len_imgs = len(self.mask_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_imgs\n",
    "\n",
    "    def apply_aug(self, x):\n",
    "      x = self.randomperspective(x)\n",
    "      x = self.randomHorizontalflip(x)\n",
    "      x = self.randomElastic(x)\n",
    "      x = self.randomRotation(x)\n",
    "      return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx][0]\n",
    "        mask_file = self.mask_files[idx]\n",
    "        label = self.image_files[idx][1]\n",
    "\n",
    "        image = read_image(image_file).float()\n",
    "        mask = read_image(mask_file).float()\n",
    "\n",
    "        # Multiply the mask onto the image\n",
    "        image = torch.mul(image, mask / 255)\n",
    "\n",
    "        image = (image).squeeze(0)\n",
    "\n",
    "        image_stacked = torch.stack([image, image, image])\n",
    "\n",
    "        if self.transform:\n",
    "            image_stacked = self.transform(image_stacked)\n",
    "\n",
    "        # One-hot encode the label\n",
    "        one_hot_label = torch.FloatTensor([self.labels_dict[label]])\n",
    "\n",
    "        return image_stacked, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ivxk1r79PEG2"
   },
   "outputs": [],
   "source": [
    "qu_ds = QULungsData('lung_seg/lung_seg/Train/', transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  ]\n",
    "                                                      ))\n",
    "train_loader = DataLoader(qu_ds, batch_size=16, shuffle=True)\n",
    "\n",
    "qu_val_ds = QULungsData('lung_seg/lung_seg/Val/', transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  ]\n",
    "                                                      ))\n",
    "val_loader = DataLoader(qu_val_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J-da19uIQ_ZD"
   },
   "outputs": [],
   "source": [
    "def save_model_and_logs(model, loss_values, accuracies, val_loss_values, save_path):\n",
    "    # Create the logs folder if it doesn't exist\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = os.path.join(save_path, 'model.pt')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Save the loss values and accuracies as numpy arrays\n",
    "    logs_path = os.path.join(save_path, 'logs.npy')\n",
    "    np.save(logs_path, {'loss_values': np.array(loss_values), 'accuracies': np.array(accuracies), \"val_losses\": np.array(val_loss_values)})\n",
    "\n",
    "    print('Model and logs saved successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D3YtLXSO7Fdi",
    "outputId": "e1b879ac-62d1-4937-cfca-9a7128bea705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating val loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculating val loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m val_loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_validation_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m val_loss_values\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m     73\u001b[0m epoch_t_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mcalculate_validation_loss\u001b[0;34m(model, val_loader, criterion)\u001b[0m\n\u001b[1;32m     23\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     26\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[12], line 54\u001b[0m, in \u001b[0;36mQULungsData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m mask \u001b[38;5;241m=\u001b[39m read_image(mask_file)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Multiply the mask onto the image\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m image \u001b[38;5;241m=\u001b[39m (image)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m image_stacked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([image, image, image])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the number of steps to plot the loss graph\n",
    "plot_interval = 25\n",
    "\n",
    "# Initialize an empty list to store the loss values\n",
    "loss_values = []\n",
    "\n",
    "val_loss_values = []\n",
    "\n",
    "epoch_t_losses = []\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Function to calculate validation loss\n",
    "def calculate_validation_loss(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted_labels = torch.round(torch.sigmoid(outputs))\n",
    "            correct_predictions += (predicted_labels == labels).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    validation_loss = total_loss / total_samples\n",
    "\n",
    "    return validation_loss, accuracy\n",
    "\n",
    "# Training loop\n",
    "for i in range(50):\n",
    "  for step, (inputs, labels) in enumerate(train_loader):\n",
    "      # Move inputs and labels to the device\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # Perform forward pass\n",
    "      outputs = new_model(inputs)\n",
    "\n",
    "      # Calculate the loss\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      print('epoch ' + str(i) + ',' +str(step) + \" step and loss is \" + str(loss))\n",
    "\n",
    "      # Store the loss value\n",
    "      loss_values.append(loss.item())\n",
    "\n",
    "      # Perform backward pass and update the model parameters\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Save validation loss every 25 steps\n",
    "      if step % 400 == 0:\n",
    "          clear_output(wait=True)\n",
    "          print('Calculating val loss')\n",
    "          val_loss, acc = calculate_validation_loss(new_model, val_loader, criterion)\n",
    "          val_loss_values.append(val_loss)\n",
    "          epoch_t_losses.append(loss.item())\n",
    "          accuracies.append(acc)\n",
    "          print('epoch ' + str(i) + ',' + str(step) + \" step and val loss is \" + str(val_loss) + \" accuracy is \" + str(acc))\n",
    "          save_model_and_logs(new_model, loss_values, accuracies, val_loss_values, './logs5')\n",
    "\n",
    "      # Plot the loss graph every 25 steps\n",
    "      if (step) % 200 == 0:\n",
    "          print('epoch ' + str(i) + ',' + str(step) + \" step and val loss is \" + str(loss))\n",
    "          plt.plot(loss_values, label='Train Loss')\n",
    "          plt.plot(val_loss_values, label='Validation Loss')\n",
    "          plt.xlabel('Steps')\n",
    "          plt.ylabel('Loss')\n",
    "          plt.title('Training and Validation Loss')\n",
    "          plt.legend()\n",
    "          plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
